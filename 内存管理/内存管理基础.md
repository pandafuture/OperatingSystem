<font size = 9>$$内存管理基础$$</font>


# 一、内存的基础知识

内存可存放数据。程序执行前 **需要先放到内存中才能被 CPU 处理** —— 缓和 CPU 与硬盘之间的速度矛盾。

为了区分各个程序的数据在内存中的位置，就需要给内存的 **存储单元（存储数据的最小单元）** 编地址。内存地址从 0 开始，**每个地址对应一个存储单元**。
- **按字节编址** 指 **每个存储单元大小** 为 **1 字节**，即 1B，即 8 个二进制位。
- **按字编址** 指 **每个存储单元大小** 为 **1 个字**，即如果 **字长为 16 位** 的计算机中，每个字的大小为 16 个二进制位。

- 常用数量级：
  - $2^{10} = 1K$，（千）
  - $2^{20} = 1M$，（兆，百万）
  - $2^{30} = 1G$，（十亿，千兆）

- **逻辑地址（相对地址）**：程序经编译、链接后生成的指令中指明的地址。即，相对于进程的起始地址而言的地址。

- **逻辑地址空间（虚拟地址空间）**：当链接程序将各个模块链接成一个完整的可执行目标程序时，链接程序顺序依次按各个模块的相对地址构成同一的从 0 号单元开始编址的逻辑地址空间。

- **物理地址（绝对地址）**：是地址转换的最终地址，进程在运行时执行指令和访问数据，最后都要通过物理地址从主存中存取。

- **物理地址空间** 是内存中物理单元的集合。

- **地址重定位**：通过地址转换将逻辑地址转换成物理地址。

- **内存管理部件（MMU）** 可供操作系统将进程使用的逻辑地址转换为物理地址。





# 二、程序的链接与装入

创建进程首先要将程序和数据 **将用户源程序变为可在内存中执行的程序**，通常 **需要以下几个步骤**：
1. **编译**：有编译程序将用户源代码编译成若干个目标模块。（就是把高级语言 **翻译为机器语言**）
2. **链接**：由链接程序将编译后形成的一组目标模块，以及所需库函数链接到一起，形成一个完整的装入模块。
3. **装入（装载）**：由装入程序将装入模块装入内存运行。


## （一）链接
对目标模块进行链接时，根据链接时间的不同，分为以下 **三种链接方式**：
1. **静态链接**：在程序运行之前，先将各目标模块及它们所需的库函数连接成一个完整的可执行文件（装入模块），之后不再拆开。
2. **装入时动态链接**：将各目标模块装入内存时，边装入边链接的链接方式。
    - 便于修改和更新。
    - 便于实现对目标模块的共享。
3. **运行时动态链接**：在程序执行中需要该目标模块时，才对它进行链接。
    - 便于修改和更新。
    - 便于实现对目标模块的共享。
    - 加快程序的装入过程。
    - 节省内存空间。




## （二）装入
**程序的装入** 有三种方式：**绝对装入**、**可重定位装入（静态重定位）**、**动态运行时装入（动态重定位）**。

1. **绝对装入**：在编译时，如果直到程序将放到内存中的哪个位置，编译程序将产生绝对地址的目标代码。装入程序按照模块中的地址，将程序和数据装入内存。
   - 绝对装入 灵活性差，**只适用于单道程序环境，无操作系统**。

2. **可重定位装入（静态重定位）**：编译、链接后的装入模块的地址都是从 0 开始的，指令中使用的地址、数据存放的地址都是相对于起始地址而言的逻辑地址。可根据内存的当前情况，将装入模块装入到内存的适当位置。装入时对地址进行 **重定位**，将逻辑地址变换为物理地址（地址变换是在装入时一次完成的）。
    - 一个作业装入内存时，**必须分配其要求的全部内存空间**，如果没有足够的内存，就不能装入该作业。
    - 作业一旦进入内存后，**在运行期间就不能再移动**，也不能再申请内存空间。
    - 适用于早期多道批处理阶段。

3. **动态运行时装入（动态重定位）**：编译、链接后的装入模块的地址都是从 0 开始的。装入程序把装入模块装入内存后，并不会立即把逻辑地址转换为物理地址，而是 **把地址转换推迟到程序真正要执行时才进行**。一次装入内存后所有的地址依然是逻辑地址。这种方式需要一个 **重定位寄存器** 的支持。
    - 重定位寄存器：存放装入模块存放的 **起始位置（起始物理地址）**。
    - 采用动态重定位时 **允许程序在内存中发生移动**。
    - 可将程序分配到不连续的存储区中
    - 在程序运行前只需装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存
    - 便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。
    - 现代操作系统使用。







# 二、内存管理的概念

**内存管理** 就是操作系统对内存的划分和动态分配。

内存管理的 **主要功能**：
  1. **内存空间的分配与回收**：由操作系统负责内存空间的分配和管理，记录内存的空闲空间、内存的分配情况，并回收已结束进程所占用的内存空间。
  2. **内存空间的扩充**：利用虚拟存储技术从逻辑上扩充内存。**实现虚拟性**。
  3. **地址转换**：**逻辑地址到物理地址的转换**（这个过程称为 **地址重定位**）应该由操作系统负责，保证了程序员写程序时不需要关注物理内存的实际情况。
      - **转换方式就是三种装入方式**。
  4. **存储保护**：**保证各个进程在各自的存储空间内运行，互不干扰，不会越界访问**。
      - 内存保护可以采取两种方法：
        - **方式一：** 在 CPU 中 **设置一对上、下限寄存器**，存放进程的上、下限地址。进程的指令要访问某个地址时，CPU 检查是否越界。
        - **方式二：** 采用 **重定位寄存器（基址寄存器）** 和 **界地址寄存器（限长寄存器）** 进行越界检查。重定位寄存器中存放的是进程的 **起始物理地址**。界地址寄存器中存放的是进程的 **最大逻辑地址**。
  5. **内存共享**：允许多个进程访问内存的同一部分。即，支持对内存共享区域进行受控访问。





# 三、进程的内存映像

当一个程序调入内存运行时，就构成了进程的 **内存映像**。

- 一个进程的 **内存映像包括**：
  - **代码段**：程序的二进制代码。是只读的，可以被多个进程共享。

  - **数据段**：程序运行时加工处理的对象。包括全局变量和静态变量。

  - **进程控制块（PCB）**：存放在系统区。操作系统通过 PCB 来控制和管理进程。

  - **堆**：存放动态分配的变量。通过调用 malloc 函数动态地向高地址分配空间。

  - **栈**：用来实现函数调用。从用户空间的最大地址往低地址方向增长。


**一个进程在内存（32位系统，进程虚拟地址存储空间为 4GB）中的映像**，如下图：

|空间地址|存储区域|空间地址|映像|存储内容|例子|
|:---:|:-----------:|:-----:|:---------:|:------------:|:------:|
|$0 \times FFFFFFFF$ <br> ~ <br> $0 \times C0000000$|操作系统内核区|$0 \times FFFFFFFF$ <br> ~ <br> $0 \times C0000000$|操作系统内核区|内核代码、内核数据结构 <br> 用户代码不可见区|进程控制块|
|$0 \times C0000000$ <br> ~|  |$0 \times C0000000$ <br> ~|用户栈 <br> （运行时创建）|由各函数的栈帧组成，包含各个局部变量、函数调用相关的信息 <br> （运行时可以动态地扩展和收缩，每调用一个函数，栈就会增长；从一个函数返回时，栈就会收缩）|在函数大括号内定义的局部变量、函数调用时传入的参数|
|~|  |~|$\downarrow$ <br> $\uparrow$|
|~|  |~ <br> $0 \times 40000000$|共享库的存储映射区|被调用的库函数 <br> 共享函数库代码所在区域|printf 函数的代码|
|~|用户区|$0 \times 40000000$ <br> ~| |
|~|  |~|$\uparrow$ <br> 堆 <br> （运行时由 malloc 创建）|malloc 分配的区域 <br> （运行时可以动态地扩展和收缩）|由 malloc / free 分配、回收的数据|
|~|  |~|读/写数据段 <br> （.data、.bss）|全局变量、静态变量 <br> （进程启动时确定大小，固定不变）|定义在函数外的全局变量、由 static 关键字修饰的变量|
|~ <br> $0 \times 08048000$|  |~ <br> $0 \times 08048000$|只读代码/数据段 <br> （.init、.text、.rodata）|程序指令、只读数据 <br> （进程启动时确定大小，固定不变）|程序代码、由 const 关键字修饰的常变量|
|$0 \times 08048000$ <br> ~ <br>$0 \times 00000000$|未使用区|$0 \times 08048000$ <br> ~ <br>$0 \times 00000000$|未使用区|

- 宏定义的常量不专门分配存储空间，而是在预编译阶段就代替代码中的数据为定义的常量。





# 四、内存空间的扩充

扩充内存空间有三种技术，**覆盖技术**、**交换技术**、**虚拟存储技术（后续会详细讲解）**。


## （一）覆盖技术

**覆盖技术** 用来 **解决“程序大小超过物理内存总和”的问题**。

1. 覆盖技术的 **思想**：将 **程序分为多个段**（多个模块）。常用的段常驻内存，不常用的段在需要时调入内存。
    - 内存中分为 **一个“固定区”** 和 **若干个“覆盖区”**。
    - 需要常驻内存的段放在“**固定区**”中，**调入后就不再调出**（除非运行结束）。
    - 不常用的段放在“**覆盖区**”，**需要用到时调入内存，用不到时调出内存**。

- **必须由程序员声明覆盖结构**，操作系统完成自动覆盖。
- **缺点**：**对用户不透明**，增加了用户编程负担。只用于早期的操作系统中。
- **覆盖是在同一个程序或进程中进行的**。




## （二）交换技术

1. 交换（对换）技术的 **思想**：内存空间紧张时，系统将内存中某些进程暂时 **换出** 外存，把外存中某些已具备运行条件的进程 **换入** 内存。（进程在内存与磁盘（外存）间动态调度）
    - **挂起状态（挂起态）**：暂时换出外存等待的进程状态。又可细分为 **就绪挂起** 和 **阻塞挂起** 两种状态。

2. 具有对换功能的操作系统中，通常把磁盘空间分为 **文件区** 和 **对换区** 两部分。
    - **文件区** 主要用于 **存放文件**，**主要追求存储空间的利用率**，因此文件区空间的管理 **采用离散分配方式**
    - **对换区** 用于 **存放被换出的进程数据**。对换区空间只占磁盘空间的很小部分。由于对换的速度直接影响到系统的整体速度，所以对换区空间的管理 **主要追求换入换出速度**，因此对换区通常 **采用连续分配方式**。
    - **对换区的 I/O 速度比文件区的更快**。

3. 交换通常在许多进程运行且内存吃紧时进行，而系统负荷降低就暂停。

4. 可优先换出的进程：
    - 阻塞进程
    - 优先级低的进程
    - 在内存的驻留时间太短的进程不会优先被换出
    **注意**：**PCB 会常驻内存**，不会被换出外存。

- **交换是在不同进程（或作业）之间进行的**。





# 五、内存空间的分配与回收

内存空间的分配与回收由两种实现方式：**连续分配管理方式** 和 **非连续分配管理方式**。


## （一）连续分配管理方式

**连续分配** 指为用户进程分配的必须是一个 **连续的内存空间**。

连续分配管理方式主要包括 **单一连续分配**、**固定分区分配**、**动态分区分配**。

### 1. 单一连续分配

1. **方法思想**：在单一连续分配方式中，内存被分为 **系统区** 和 **用户区**。
   - 系统区仅供操作系统使用，用于存放操作系统的相关数据，通常位于内存的低地址部分。
   - 用户区用于存放用户进程相关数据。
   - 内存中 **只能有一道用户程序**，即用户区内存中仅有一道用户程序，用户程序独占整个用户区空间。

2. **优点**：
    - 实现简单。
    - **无外部碎片（内存中由于太小而难以利用的空闲分区）**。
    - 可以采用覆盖技术扩充内存。
    - 不一定需要采用内存保护。因为系统中永远只有一道程序。

3. **缺点**：
    - 只能用于单用户、单任务的操作系统中。不支持多道程序并发运行。
    - **有内部碎片**（分配给某进程的内存区域中，某些没有用上的部分）。
    - 存储区利用率极低。



### 2. 固定分区分配

1. **方式思想**：将整个 **用户内存空间** 划分为 **若干个固定大小的分区**，在 **每个分区中只装入一道作业**。
    - 划分分区时有两种方法：
      - **分区大小相等**：缺乏灵活性，但很 **适合用于一台计算机控制多个相同对象的场合**。
      - **分区大小不等**：增加了灵活性，可以满足不同大小的进程需求。根据常在系统中运行的作业大小情况进行划分。
    - **分区说明表** 实现各个分区的分配与回收。
      - 每个表项对应一个分区，通常按分区大小排列。
      - 每个表项包括对应分区的 **大小**、**起始地址**、**状态（是否已分配）**。
    - 分配内存时，由操作系统内核程序根据用户程序大小检索该表，以找到一个能满足大小的、未分配的分区，将之分配给该程序，并将对应表项的状态置为“已分配”；若无适合分区，则拒绝分配。回收内存时，只需将对应表项的状态置为“未分配”即可。

2. **优点**：实现简单，**无外部碎片**。

3. **缺点**：
    - 用户程序太大时，可能所有分区都不能满足需求，此时不得不采用覆盖技术来解决，但这又会降低性能。
    - **会产生内部碎片**，内存利用率低。



### 3. 动态分区分配

**动态分区分配（可变分区分配）** 这种分配方式 **不会预先划分内存分区**，而是在进程装入内存时，**根据进程的大小动态地建立分区**，并使分区的大小正好适合进程的需要。
- 系统分区的大小和数目是可变的。

- 系统可采用两种数据结构来记录内存的使用情况：
  - **空闲分区表**：每个空闲分区对应一个表项。表项中包含 **分区号**、**分区大小**、**分区起始地址** 等信息
  - **空闲分区链**：每个分区的起始部分和末尾部分分别设置前项指针和后向指针。起始部分还可记录分区大小等信息。

- 把一个写作业装入内存时，必须按照一定的 **动态分区分配算法**，从空闲分区表（或空闲分区链）中选出一个分区分配给该作业。

- 回收内存分区时，可能遇到四种情况：
  - 回收区 **之后有** 相邻的空闲分区。将 **两个分区合并**，**修改后一分区表项的始址和大小**。
  - 回收区 **之前有** 相邻的空闲分区。将 **两个分区合并**，**修改前一分区表项的大小为两者之和**。
  - 回收区 **前、后都有** 相邻的空闲分区。将 **三个分区合并**，**修改前一分区表项的大小为三者之和，并取消后一分区表项**。
  - 回收区 **前、后都没有** 相邻的空闲分区。为回收区 **新建一个表项**，**填写始址和大小，并插入空闲分区链（表）**。

- 动态分区分配 **没有内部碎片**，但是 **有外部碎片**。

- 如果内存中空闲空间的总和本来可以满足某进程的要求，但由于进程需要的是一整块连续的内存空间，因此这些“碎片”不能满足进程的需求。可以通过 **紧凑（拼凑）** 技术来解决外部碎片。
  - **紧凑技术**：操作系统不时地对进程进行移动和整理。需要动态重定位寄存器的支持，相对耗时。

**动态分区分配算法** 有四种，分别为 **首次适应算法（First Fit）**、**最佳适应算法（Best Fit）**、**最坏适应算法（Worst Fit）**、**邻近适应算法（Next Fit）**。

1. **首次适应算法**
   - **算法思想**：每次都从低地址开始查找，找到第一个能满足大小的空闲分区。
   - **实现**：**空闲分区以地址递增的次序排列**。每次分配内存时查找 **空闲分区链**（或 **空闲分区表**），找到大小能满足要求的第一个空闲分区。
   - **优点**：综合看性能最好。**算法开销小**，回收分区后一般不需要对空闲分区队列重新排序。

2. **最佳适应算法**
    - **算法思想**：由于动态分配分区是一种连续分配的方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区，即，优先使用更小的空闲区。
    - **实现**：空闲分区 **按容量递增次序链接**（按容量递增的次序排列）。每次分配内存时顺序查找 **空闲分区链**（或 **空闲分区表**），找到大小能满足要求的第一个空闲分区。
    - **缺点**：**每次都选最小的分区进行分配，会留下越来越多的、很小的、难以利用的内存块。因此这种方法会产生很多（最多）外部碎片**。

3. **最坏适应算法（最大适应算法）**
    - **算法思想**：为了解决最佳适应算法会留下太多难以利用的小碎片的问题，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。
    - **实现**：空闲分区 **按容量递减次序链接**。每次分配内存时顺序查找 **空闲分区链**（或 **空闲分区表**），找到大小能满足要求的第一个空闲分区。
    - **缺点**：**每次都选最大的分区进行分配，虽然可以让分配后留下的空闲区更大，更可用，但会导致较大的连续空闲区被迅速用完。如果之后有“大进程”到达，就没有内存分区可用了。

4. **邻近适应算法（环首次适应算法）**
    - **算法思想**：首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也会增加查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决整个问题。
    - **实现**：空闲分区 **以地址递增的顺序排列**（可排成一个循环链表）。每次分配内存时 **从上次查找结束的位置开始** 查找 **空闲分区链**（或 **空闲分区表**），找到大小能满足要求的第一个空闲分区。
    - **缺点**：可能会导致无论低地址、高地址部分的空闲分区都有相同的概率被使用，也就导致了高地址部分的大分区更可能被使用，划分为小分区，最后导致无大分区可用。




## （二）非连续分配管理方式

**非连续分配** 指为用户进程分配的可以是一些 **分散的内存空间**。

非连续分配方式根据 **分区大小是否固定**，分为 **分页存储管理** 和 **分段存储管理**。

**分页存储管理** 根据 **运行作业时是否要将作业的所有页面都装入内存才能运行**，分为 **基本分页存储管理** 和 **请求分页存储管理**。


### 1. 基本分页存储管理

1. **基本分页存储管理思想**
   - 将内存空间分为一个个 **大小相等的分区**，每个分区就是一个“**页框（页帧/内存块/物理块/物理页面）**”。每个页框有一个编号，即“**页框号（页帧号/内存块号/物理块号/物理页号）**”，页框号 **从 0 开始**。
   - 将 **进程的逻辑地址空间** 也分为 **与页框大小相等** 的一个个部分，每个部分称为一个 **页** 或 **页面**。每个页面也有一个编号，即 **页号**，页号也是 **从 0 开始**。
   - 操作系统 **以页框为单位为各个进程分配** 内存空间。进程的每个页面分别放入一个页框中。即，进程的 **页面**与内存的 **页框** 有 **一一对应** 的关系。
      - 各个页面不必连续存放，可以放到不相邻的各个页框中。
      - **分页管理不产生外部碎片**。

2. **页表**
为了便于找到进程的每个页面在内存中存放的位置，系统为每个进程建立了一张 **页面映射表（页表）**。
     - 页表通常存在 PCB 中。
     - 进程的每个页面对应一个 **页表项**
     - 每个 **页表项** 由 **页号** 和 **块号** 组成，记录了 **页面在内存中对应的物理块号**。
     - 可以由计算机中 **内存块的数量** 推出页表项中 **块号至少占多少字节**。
     - 页表中的 **页号** 可以是 **隐含** 的，即 **页号不占用存储空间**。
     - 页表的 **作用** 是 **实现从页号到物理块号的地址映射**。
     - **每个页表项的长度（大小）是相同的**。
   *注意*：页表记录的只是内存块号，而不是内存块的起始地址。  
   **$$i 号页表项存放地址 = 页表始址 + i * 页表项大小$$**
   **$$J 号内存块的起始地址 = J * 内存块大小$$**

3. **实现地址的转换**
虽然进程的各个页面是离散存放的，但是页面是连续存放的。
     - **逻辑地址** 可以拆分为 **页号**、**页内偏移量**。

    **基本思路**：
      1. 确定逻辑地址 A 对应的“**页号**” P
      2. 找到 P 号页面在内存中的起始地址（需要查页表）
      3. 确定逻辑地址 A 的“**页内偏移量**” W
        **$$逻辑地址 A 对应的物理地址 = P 号页面在内存中的起始地址 + 页内偏移量 W$$**
        **$$页号 = 逻辑地址 / 页面长度（取除法的整数部分）$$**
        **$$页内偏移量 = 逻辑地址 \% 页面长度（取除法的余数部分）$$**
     - 计算机内部，地址是用二进制表示的，如果 **页面大小** 刚好是 **2 的整数幂**，则计算机硬件可以很快速的把逻辑地址拆分成（页号，页内偏移量）。即，如果每个页面大小为 **$2^K$B**，用二进制数表示逻辑地址，则 **末尾 K 位** 即为 **页内偏移量**，其余部分就是 **页号**。（只需把页表中记录的 **物理块号拼接上页内偏移量** 就能得到对应的 **物理地址**）

4. 分页存储管理的 **逻辑地址结构**
    - 地址结构包含两部分：
      - 前一部分为页号
      - 后一部分为页内偏移量

    |31   ......   12|11   ...   0|
    |:--------------:|:----------:|
    |     页号 P     | 页内偏移量 W |

      - 如果有 **K 位** 表示 **页内偏移量**，则说明该系统中 **一个页面的大小是 $2^K$ 个内存单元**。
      - 如果有 **M 位** 表示 **页号**，则说明该系统中 **一个进程最多允许有 $2^M$ 个页面**。

5. **基本地址变换机构**
**基本地址变换机构** 用于实现 **将逻辑地址转换为内存中的物理地址**。
   - **地址变换** 是借助于页表实现的。

   - **页表寄存器（PTR）** 用来存放 **页表在内存中的起始地址 F** 和 **页表长度 M**。

   - 进程未执行时，页表的始址和页表长度 **放在进程控制块（PCB）中**，当进程被调度时，操作系统内核会把它们放到页表寄存器中。

   - **地址变换过程**：
       1. 根据逻辑地址 **计算出页号 P、页内偏移量 W**。
       2. 判断页号是否越界。
          - **比较页号 P 和页表长度 M，如果 $P \geq M$，则产生越界中断，否则继续执行**。
          - 注意：页号是从 0 开始的，而页表长度至少是 1,因此 **$P = M$ 时也会越界**
       3. 查询页表，找到页号对应的页表项，确定页面存放的内存块号。（**CPU 第一次访问内存**）
          - 页表中页号 P 对应的 **$页表项地址 = 页表起始地址 F + 页号 P * 页表项长度$**，取出 **页表项内容 b**，即为内存块号。
          - 注意区分 **页表项长度**、**页表长度**、**页面大小** 的区别
            - **页表项长度**：每个页表项占多大的存储空间。
            - **页表长度**：这个页表中总共有几个页表项。
            - **页面大小**：一个页面占多大的存储空间。
       4. 用内存块号和页内偏移量得到物理地址。
           - 计算 **$E = b * L + W$**，得到物理地址 E 去访存。
           - 如果内存块号、页内偏移量是用二进制表示的，那么把二者拼接起来就是最终的物理地址了。
       5. 访问目标内存单元。（**CPU 第二次访问内存**）

    - CPU 从得到想要访问的逻辑地址到实际访问到内存单元，这个过程中共需要 **进行两次访问内存** 的操作。
    - **页式管理中地址是一维的**。
    - 进程页表通常是 **装在连续的内存块中** 的。

6. **具有快表的地址变换机构**
**快表（TLB，相联寄存器）** 是一种 **访问速度比内存快很多** 的高速缓存（**TLB 不是内存！**），用来存放 **最近访问的页表项的副本**，可以加速地址变换的速度。
   - 快表是一种高速缓冲存储器，是一种硬件。
   - 与此对应，内存中的页表常称为 **慢表**。
   - **引入快表后，地址变换过程**：
        1. CPU 给出逻辑地址，有某个硬件算得页号、页内偏移量，将页号与快表中的所有页号进行比较。
        2. 如果找到匹配的页号，说明要访问的页表项在快表中有副本，则直接从中取出该页对应的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后 **访问** 该物理地址对应的 **内存单元**。因此，若 **快表命中**，则访问某个逻辑地址仅需 **一次访存** 即可。
        3. 如果没有找到匹配的页号，则需要 **访问内存中的页表**，找到对应页表项，得到页面存放的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后 **访问** 该物理地址对应的 **内存单元**。因此，若 **快表未命中**，则访问某个逻辑地址需要 **两次访存**（**注意：在找到页表项后，应同时将其存入快表**，以便后面可能的再次访问。但若快表已满，则必须按照一定的算法对旧的页表项进行替换）。
   - 由于查询快表的速度比查询页表的速度快很多，因此只要快表命中，就可以节省很多时间。
   - 基于 **局部性原理**，一般快表的命中率可达 $90\%$ 以上。
     - **时间局部性**：如果执行了程序中某条指令，那么不久后这条指令很有可能再次执行；如果某个数据被访问过，不久之后该数据很可能再次被访问。（因为程序中存在大量的循环）
     - **空间局部性**：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。（因为很多数据在内存中都是连续存放的）
   - 有的系统支持 **快表和慢表同时查找**。
   - TLB 和 普通 Cache 的区别：**TLB 中只有页表项的副本**，而普通 Cache 中可能会有其他各种数据的副本。

1. **两级页表**
   - 单极页表的问题：
     - **所有页表项都连续存放，当页表很大时，需要占用很多个连续的页框**。
     - 没有必要让整个页表常驻内存，因为进程在一段时间内可能只需要访问某几个特定的页面。

    **单极页表问题一解决方案**：可 **将长长的页表进行分组**，使每个内存块刚好可以放入一个分组，另外要 **将离散分配的页表再建立一张页表**，称为 **页目录表**（**外层页表**/**顶层页表**）。

    - 逻辑地址空间格式：

        |31 ... 22|21 ... 12|11 ... 0|
        |:-------:|:-------:|:------:|
        |一级页号/页目录号|二级页号|页内偏移量|

    - **地址变换**
        1. 按照地址结构将逻辑地址拆分为三个部分
        2. 从 PCB 中读出页目录表始址，再根据一级页号查页目录表，找到下一级页表在内存中的存放位置。
        3. 根据二级页号查表，找到最终想访问的内存块号。
        4. 结合页内偏移量得到物理地址。

    **单极页表问题二解决方案**：可以在需要访问页面时才把页面调入内存（虚拟存储技术）。可以在页表项中增加一个 **标志位**，用于表示该页面是否已经调入内存。
     - 若想访问的页面不在内存中，则产生缺页中断（内中断），然后将目标页面从外存调入内存。

- **注意**：
  - 若采用多级页表机制，则 **各级页表的大小不能超过一个页面**。若两级页表不够，可以分更多级。
  - 两级页表的 **访存次数** 分析（假设没有快表机构）
    - 第一次访存：访问内存中的页目录表
    - 第二次访存：访问内存中的二级页表
    - 第三次访存：访问目标内存单元
    - **N 级页表访问一个逻辑地址需要 N + 1 次访存**。



### 2. 基本分段存储管理

1. **分段**
**分段系统** 把 **进程的空间地址** 按照 **自身的逻辑** 关系 **划分为若干个段**，每个段都有一个 **段名**（在低级语言中，程序员使用段名来编程），**每段从 0 开始编址**。
**内存分配规则**：以段为单位进行分配，**每个段在内存中占据连续空间**，但 **各段之间可以不相邻**。（段内要求连续、段间不要求连续）
   - 编译程序会将段名转换为段号。

   - 分段系统的 **逻辑地址结构** 由 **段号（段名）** 和 **段内地址（段内偏移量）** 所组成。

        |31 ... 16|15 ... 0|
        |:-------:|:------:|
        |段号|段内地址|

        - **段号的位数决定了每个进程最多可以分几个段**。
        - **段内地址位数决定了每个段的最大长度是多少**。

2. **段表**
**段表** 是为每个进程建立的一张逻辑空间与内存空间的映射表。
   - 作用：程序分多个段，各段离散地装入内存，为了保证程序能正常运行，可以通过段表从物理内存中找到各个逻辑段的存放位置。
   - 进程的每个段对应一个 **段表项**，其中记录了该段在内存中的 **段号**、**起始位置（基址）** 和 **段的长度**。

        |段号|段长|本段在主存中的始址（基址）|
        |:-:|:--:|:----------------------:|

        - 分段系统中，段长是由用户显式提供的。
        - **各个段表项的长度是相同的**。
        - **段号可以是隐含的，不占存储空间**。因为段表项长度相同。
        - 若段表存放的起始地址为 M，则 K 号段对应的段表项存放的地址为 M + K * 段表项的长度。

3. **实现地址的转换**
   1. 根据逻辑地址得到段号 S、段内地址 W。
   2. 判断段号是否越界。若 $段号 S \geq 段表长度 M$，则产生越界中断，否则继续执行。
        - 注意：段表长度至少是 1，而段号从 0 开始。
   3. 查询段表，找到对应的段表项，段表项的存放地址为 $段表始址 F + 段号 S * 段表项长度$。
   4. 检查段内地址是否超过段长。若 $段内地址 W \geq 段长 C$，则产生越界中断，否则继续执行。
   5. 计算得到物理地址。$段基址 b + 段内地址 W$。
   6. 访问目标内存单元。

- **分段** 访问一个逻辑地址需要 **两次访存**。
  - 第一次访存：查内存中的段表。
  - 第二次访存：访问目标内存单元。
- 分段系统也 **可以引入快表机构**，将近期访问过的段表项放到快表中，这样 **可以少一次访问**，加快地址变换速度。

**分段、分页管理的对比**
- **页** 是 **信息的物理单位**。分页的主要目的是为了实现离散分配，提高内存利用率。分页仅仅是系统管理上的需要，完全是系统行为，**对用户是不可见的**。
- **段** 是 **信息的逻辑单位**。分段的主要目的是更好地满足用户需求。一个段通常包含着一组属于一个逻辑模块的信息。**分段对用户是可见的**，用户编程时需要显式地给出段名。
- 页的大小固定且由系统决定。段的长度却不固定，决定于用户编写的程序。
- **分页** 的用户进程 **地址空间是一维的**，程序员只需给出一个记忆符即可表示一个地址。
- **分段** 的用户进程 **地址空间是二维的**，程序员在标识一个地址时，既要给出段名，也要给出段内地址。
- **分段** 比分页 **更容易实现信息的共享和保护**。
  - 只需让各进程的段表项指向同一个段即可实现共享。
  - 不能被修改的代码称为 **纯代码** 或 **可重入代码**（不属于临界资源），这样的代码是可以共享的。可修改的代码是不能共享的。
  - 页面不是按逻辑模块划分的。就很难实现共享。

  | |优点|缺点|
  |:-:|:--:|:--:|
  |分页管理|内存空间利用率高，**不会产生外部碎片**，只有少量的页内碎片。|不方便按照逻辑模块实现信息的共享和保护|
  |分段管理|很方便按照逻辑模块实现信息的共享和保护|如果段长过大，为其分配很大的连续空间会很不方便。另外，段式管理 **会产生外部碎片**。|

  - 分段管理中产生的外部碎片可以用“紧凑”来解决，但需要付出较大的时间代价。



### 3. 段页式管理方式

1. **段页式管理方式思想**：进程的地址空间按逻辑模块被分成若干逻辑段，每段都有自己的段号，然后将各段分成若干大小固定的页。再将内存空间分为大小相同的内存块/页框/页帧/物理块。

2. **逻辑地址结构**
段页式系统中，进程的逻辑地址分为 **段号**、**页号**、**页内偏移量**。

    |31 ...... 16|15 ...... 12|11 ...... 0|
    |:----------:|:----------:|:---------:|
    |段号|页号|页内偏移量|

    - **段号的位数决定了每个进程最多可以分几个段**。
    - **页号位数决定了每个段最大有多少页**。
    - **页内偏移量决定了页面大小、内存块大小是多少**。
    - 分段对用户是可见的，需要编程时显式地给出段号、段内地址。
    - 分页对用户时不可见的，系统会根据段内地址自动划分页号和页内偏移量。
    - **段页式** 管理的 **地址结构是二维的**。

3. **段表、页表**
   1. **段表**：每个段对应一个段表项，每个段表项由 **段号（隐含）**、**页表长度**、**页表存放块号（页表起始地址）** 组成。
      - 每个 **段表项长度相等**。
   2. **页表**：每个段有一张 **页表**，每个页表项包括 **页号（隐含）**、**块号**。
      - 每个 **页表项长度相等**。

4. **地址转换**
系统中有一个 **段表寄存器**，指出进程的段表始址 F 和段表长度 M 。用来在段表中寻址，和判断是否越界。
   1. 根据逻辑地址得到段号 S、页号 P、页内偏移量 W。
   2. 判断段号是否越界。若 $段号 S \geq 段表长度 M$，则产生越界中断，否则继续执行。
   3. 查询段表，找到对应的段表项，段表项的存放地址为 $段表始址 F + 页号 S * 段表项长度$。（**第一次访存**）
   4. 检查页号是否越界，若 $页号 P \geq 页表长度$，则发生越界中断，否则继续执行。
   5. 根据页表存放块号、页号查询页表，找到对应页表项。（**第二次访存**）
   6. 根据内存块号、页内偏移量得到最终的物理地址。
   7. 访问目标内存单元。（**第三次访存**）
   - 也可以引入快表机构，用段号和页号作为查询快表的关键字。若快表命中则仅需一次访存。





# 六、传统管理方式的特征、缺点

```mermaid
graph LR
  1(传统存储管理) --- 2(连续分配) & 3(非连续分配)
  2 --- 4(单一连续分配) & 5(固定连续分配) & 6(动态连续分配)
  3 --- 7(基本分页存储管理) & 8(基本分段存储管理) & 9(基本段页式存储管理)

  linkStyle 0,1,2,3,4,5,6,7 stroke:white
```

**特征、缺点**
- **一次性**：**作业必须一次性全部装入内存后才能开始运行**。会造成：
  - 作业很大时，不能全部装入内存，导致 **大作业无法运行**。
  - 当大量作业要求运行时，由于内存无法容纳所有作业，因此只能有少量作业能运行，导致 **多道程序并发度下降**。

- **驻留性**：一旦作业被装入内存，就 **会一直驻留在内存中**，直至作业运行结束。事实上，在一个时间段内，只需要访问作业的一小部分数据即可正常运行，这就导致了内存中会驻留大量的、暂时用不到的数据，浪费了宝贵的内存资源。

可以用 **虚拟存储技术** 解决传统存储管理方式的缺点。